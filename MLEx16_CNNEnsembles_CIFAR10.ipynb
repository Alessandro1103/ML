{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alessandro1103/ML/blob/main/MLEx16_CNNEnsembles_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3GYzNWONtju"
      },
      "source": [
        "# Machine Learning Exercise 16\n",
        "\n",
        "# CNN Ensembles - CIFAR10\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDEJU1RwoIlv"
      },
      "source": [
        "##Import\n",
        "\n",
        "Import libraries and print some versions.\n",
        "\n",
        "To use GPU, set `Edit / Notebook settings / Hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSKuPnIXNoq2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "c6a8c6cb-e591-4f82-f842-b8f661a57d2d"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "print(\"Tensorflow version %s\" %tf.__version__)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.15.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fd7b4dab7a7e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaeLRpWIfO1m"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Load training data from Keras library\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kECuF5cgxxW"
      },
      "source": [
        "def load_cifar10():\n",
        "    # load data\n",
        "    (Xtrain,Ytrain), (Xtest, Ytest) = tf.keras.datasets.cifar10.load_data()\n",
        "    print(Ytrain.shape)\n",
        "    # get information\n",
        "    ninput = Xtrain.shape[0]\n",
        "    imgsize = (Xtrain.shape[1], Xtrain.shape[2])\n",
        "    input_shape = (Xtrain.shape[1], Xtrain.shape[2], Xtrain.shape[3])\n",
        "    ntest = Xtest.shape[0]\n",
        "    num_classes = np.max(np.unique(Ytrain)) + 1\n",
        "    print(\"Training input %s\" %str(Xtrain.shape))\n",
        "    print(\"Training output %s\" %str(Ytrain.shape))\n",
        "    print(\"Test input %s\" %str(Xtest.shape))\n",
        "    print(\"Test output %s\" %str(Ytest.shape))\n",
        "    print(\"Input shape: %s\" %str(input_shape))\n",
        "    print(\"Number of classes: %d\" %num_classes)\n",
        "\n",
        "    # normalize input to [0,1]\n",
        "    Xtrain = Xtrain / 255.0\n",
        "    Xtest = Xtest / 255.0\n",
        "\n",
        "    # Transform output to one-out-of-n encodingmembers\n",
        "    Ytrain = tf.keras.utils.to_categorical(Ytrain, num_classes)\n",
        "    Ytest = tf.keras.utils.to_categorical(Ytest, num_classes)\n",
        "\n",
        "    return [Xtrain,Ytrain,Xtest,Ytest,input_shape,num_classes]\n",
        "\n",
        "[Xtrain,Ytrain,Xtest,Ytest,input_shape,num_classes] = load_cifar10()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6DMvR8TzJiK"
      },
      "source": [
        "## Show random image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0N3cUSazRcJ"
      },
      "source": [
        "i = random.randrange(0,Xtrain.shape[0])\n",
        "image = Xtrain[i]\n",
        "image = np.array(image, dtype='float')\n",
        "\n",
        "label = Ytrain[i].argmax()  # categorical from one-hot-encoding\n",
        "print(label)\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1EwWO9m3bGg"
      },
      "source": [
        "##CNN ensemble model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DTCwfVg3jRX"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
        "                         Conv2D, MaxPool2D, Input, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# single model\n",
        "def CNN(input_shape, num_classes, base_width=16, depth=4):\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    image_size = input_shape[0]\n",
        "    filters = base_width\n",
        "    kernel_size = 3\n",
        "    # feature extractor\n",
        "    for i in range(depth):\n",
        "        if i == 0:\n",
        "            x = Conv2D(filters=filters,\n",
        "                       kernel_size = kernel_size,\n",
        "                       activation=\"relu\",\n",
        "                       strides=1,\n",
        "                       padding=\"same\")(inputs)\n",
        "        else:\n",
        "            x = Conv2D(filters=filters,\n",
        "                       kernel_size = kernel_size,\n",
        "                       activation=\"relu\",\n",
        "                       strides=1,\n",
        "                       padding=\"same\")(x)\n",
        "        x = MaxPool2D(pool_size=(2,2), strides=(2,2), padding=\"valid\")(x)\n",
        "        filters *= 2\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# ensemble model\n",
        "def Ensemble(ens_dim, input_shape, num_classes, base_width=16, depth=4):\n",
        "  inputs = Input(shape=input_shape)\n",
        "\n",
        "  learners = [CNN(input_shape,\n",
        "                  num_classes,\n",
        "                  base_width,\n",
        "                  depth) for _ in range(ens_dim)]\n",
        "\n",
        "  outputs = [learners[i](inputs) for i in range(ens_dim)]\n",
        "\n",
        "  ensemble_model = Model(inputs, outputs, name=\"ensemble_model\")\n",
        "  optimizer = 'adam'\n",
        "  # an independent loss for each model\n",
        "  losses = [\"categorical_crossentropy\" for _ in range(ens_dim)]\n",
        "  ensemble_model.compile(loss=losses, optimizer=optimizer, metrics=['accuracy'])\n",
        "  return ensemble_model\n",
        "\n",
        "\n",
        "# create the ensemble model\n",
        "ens_dim = 3\n",
        "model = Ensemble(ens_dim, input_shape, num_classes)\n",
        "model.summary()\n",
        "\n",
        "# single model summary\n",
        "model.get_layer(index=-1).summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train setup"
      ],
      "metadata": {
        "id": "FqebCYXQEgu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "def test_accuracy(model, history):\n",
        "    # accuracy\n",
        "    ind_test_acc = []\n",
        "    for key in history.history.keys():\n",
        "      if (\"val\" in key) and (\"accuracy\" in key):\n",
        "        ind_test_acc.append(history.history[key][-1])\n",
        "    print(\"Single models test accuracy: \", ind_test_acc)\n",
        "\n",
        "    # ensemble test accuracy\n",
        "    preds = np.array(model.predict(Xtest))\n",
        "    # average over the ensemble\n",
        "    preds_ens = np.mean(preds, axis=0)\n",
        "    ens_test_acc = accuracy_score(np.argmax(Ytest, axis=-1), np.argmax(preds_ens, axis=-1))\n",
        "    print(\"Ensemble test accuracy: \", ens_test_acc)\n",
        "\n",
        "    return ind_test_acc, ens_test_acc\n",
        "\n",
        "\n",
        "history = tf.keras.callbacks.History()\n",
        "ind_test_accuracy = []\n",
        "ens_test_accuracy = []"
      ],
      "metadata": {
        "id": "YFHsYsABEjJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egL15iQztTDH"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKOdDvgf5YlZ"
      },
      "source": [
        "epochs = 5\n",
        "for _ in range(epochs):\n",
        "    model.fit(Xtrain, [Ytrain for _ in range(ens_dim)], batch_size=32, epochs=1, callbacks=[history], validation_data = (Xtest,[Ytest for _ in range(ens_dim)]))\n",
        "\n",
        "    iacc, eacc = test_accuracy(model, history)\n",
        "    ind_test_accuracy.append(iacc)\n",
        "    ens_test_accuracy.append(eacc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPtbelKYHy4K"
      },
      "source": [
        "##Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkx4x2M3vFpk"
      },
      "source": [
        "## Compare single networks with ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ind_test_accuracy)\n",
        "print(ens_test_accuracy)\n"
      ],
      "metadata": {
        "id": "UFoJuRj5DPUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EMeKtRTkRHM"
      },
      "source": [
        "plt.plot(ind_test_accuracy, label=\"Single network\")\n",
        "plt.plot(ens_test_accuracy, linestyle=\"--\", label=\"Ensemble of {} nets\".format(ens_dim))\n",
        "plt.legend()\n",
        "plt.ylabel('test accuracy')\n",
        "plt.xlabel('epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m99lALugmEzQ"
      },
      "source": [
        "# Home Exercises\n",
        "\n",
        "**Question 1**\n",
        "\n",
        "Evaluate the performance of ensembles varying the number of base members."
      ]
    }
  ]
}